# Dataset Mini Analysis
  This repository contains the Python code that I wrote to process the three practice data sets that you sent over to me. They contain vaccination data for a wide range of subjects and vaccination types, as well as their recorded antibody measurements after different periods of time. I first started by modifying the data (which was in a csv file) to alter the measurement column. I had to change all the measurement values to log_2(measurement / 5) in order to work with the data, as recommended by you. This portion of the data was in its own file called transform.py and outputted another data set called transformedSampleSets.csv, both of which are in the repository.
  I then decided to follow your general recommendation of finding out how time affected the antibody measurements from day 0 to post day 200. I wrote code to find out the percent change in the measurements from day 0 to day >200 for each vaccination, for each subject. I used these measurements to compile some standard statistics like mean, median, mode, and standard deviation for the percent change in antibody measurements for each vaccine type. I ran into an issue with percent changes of Inf or NaN, from starting measurements of 0.0 and dividing by 0, so I wrote a similar method to compile these statistics using the log difference as a different method of measuring the change in measurements to avoid undefined results.
  With this data, I tried populating some graphs/figures using matplotlib, however, the figures didn’t display the data as expected. I was debating whether to continue to use matplotlib to express the data visually (was trying to create histograms), or converting the data my methods collected into a JSON format and exporting this data to another platform to create these figures. This was how I wanted to visually observe statistically significant correlation between change antibody response measurements over time, and I can certainly finish this up by the end of the week. 
  I am still getting used to working with Python, as I had basic familiarity with its syntax, but did not know the full extent to its built-in methods and tools, as well as the capabilities of the pandas and numpy extensions that I used for this mini analysis. I used python documentation, stack overflow, and some AI to gain reference for different methods to simplify longer tasks as well as learn to use some pandas and numpy tools that I am sure I will be using much more of in the future. I am also learning about how to use some AI models to delve deeper into analyzing this type of data, and I would be happy to build upon my current work with this provided data using some more advanced tools before my internship starts. 

# Summer Program Applications for Funding
  I went to talk to the office at the Undergraduate Research Hub, and through them I was able to narrow down 3 or 4 programs that were either a good fit for my background or the nature of the research I will be doing. Through them, I scheduled a meeting with one of the program directors for summer scholarships and research stipends/funding. Unfortunately, she told me that the application for these UCSD programs closed in February, well before I was planning on taking this internship role at LJI. It is unfortunate, but it does not deter my excitement for working at LJI this summer at all, and I’d still be thrilled to be a part of the team. 
